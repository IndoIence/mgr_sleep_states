{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from MyEDFImports import load_all_labels, stages_names_3_outputs, three_stages_transform\n",
    "from tempfile import TemporaryDirectory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:06:13.465542103Z",
     "start_time": "2023-07-11T17:06:11.410662834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:06:50.976348708Z",
     "start_time": "2023-07-11T17:06:48.105317102Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'images_cwt_ssq/images_(19248, 224, 224)_wav_morlet_sqpy.npy'\n",
    "data_np = np.load(data_dir)\n",
    "targets = load_all_labels()\n",
    "targets = three_stages_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class DatasetFromNp(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        # Extending 1channel image to be put to three channels\n",
    "        x = torch.from_numpy(x)\n",
    "        x = torch.unsqueeze(x, 0)\n",
    "        x = x.expand(3, -1, -1)\n",
    "        y = self.target[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:07:52.456826690Z",
     "start_time": "2023-07-11T17:07:52.452093223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# setting up tranforms for the images (just normalizing pretty much)\n",
    "data_transforms = transforms.Compose([\n",
    "    # to tensor can probably be just torch.from_numpy\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset_all = DatasetFromNp(data_np, target=targets, transform=data_transforms)\n",
    "\n",
    "generator = torch.Generator()  # .manual_seed(22)\n",
    "train_data, test_data = random_split(dataset_all, [0.8, 0.2], generator=generator)\n",
    "datasets = {'train': train_data, 'val': test_data}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in\n",
    "               ['train', 'val']}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "# remove a fixed generator for training\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:07:54.917118138Z",
     "start_time": "2023-07-11T17:07:54.871765131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# this imshow should be fixed doesn't work yet\n",
    "def imshow(inp, title=None):\n",
    "    # inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # mean = np.array([0.485, 0.456, 0.406])\n",
    "    # std = np.array([0.229, 0.224, 0.225])\n",
    "    # inp = std * inp + mean\n",
    "    # inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "# not necessarily test_data subset has to be there can be anything else\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "grid = torchvision.utils.make_grid(inputs)\n",
    "# imshow(grid, title= classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T09:34:40.325149876Z",
     "start_time": "2023-06-16T09:34:40.012436Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    # No idea why now for inputs why I need to transfer it to a float from a double\n",
    "                    inputs = inputs.to(device, dtype=torch.float)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T09:34:40.334016581Z",
     "start_time": "2023-06-16T09:34:40.330769262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "2048"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_152 = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "num_ftrs = model_152.fc.in_features\n",
    "num_ftrs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:07:21.454601402Z",
     "start_time": "2023-07-11T17:07:20.492990493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model_152.fc = nn.Linear(num_ftrs,3)\n",
    "model_152.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_152 = optim.SGD(model_152.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_152, step_size=7, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T09:34:41.314008856Z",
     "start_time": "2023-06-16T09:34:41.158008144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 0.8587 Acc: 0.6537\n",
      "val Loss: 0.9394 Acc: 0.6345\n",
      "\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 0.7049 Acc: 0.7217\n",
      "val Loss: 0.9643 Acc: 0.5310\n",
      "\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 0.6087 Acc: 0.7604\n",
      "val Loss: 0.9421 Acc: 0.6345\n",
      "\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 0.5300 Acc: 0.7949\n",
      "val Loss: 0.9875 Acc: 0.6261\n",
      "\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 0.4850 Acc: 0.8138\n",
      "val Loss: 1.0176 Acc: 0.6339\n",
      "\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 0.4497 Acc: 0.8245\n",
      "val Loss: 0.9691 Acc: 0.6345\n",
      "\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 0.4079 Acc: 0.8441\n",
      "val Loss: 0.9163 Acc: 0.6345\n",
      "\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 0.3011 Acc: 0.8898\n",
      "val Loss: 1.3557 Acc: 0.1839\n",
      "\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 0.2678 Acc: 0.8989\n",
      "val Loss: 0.8414 Acc: 0.6547\n",
      "\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 0.2458 Acc: 0.9072\n",
      "val Loss: 0.8368 Acc: 0.6581\n",
      "\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 0.2295 Acc: 0.9144\n",
      "val Loss: 0.3117 Acc: 0.8844\n",
      "\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 0.2138 Acc: 0.9193\n",
      "val Loss: 1.9859 Acc: 0.1855\n",
      "\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 0.1964 Acc: 0.9277\n",
      "val Loss: 0.3111 Acc: 0.8867\n",
      "\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 0.1808 Acc: 0.9336\n",
      "val Loss: 1.1081 Acc: 0.5931\n",
      "\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9468\n",
      "val Loss: 0.3195 Acc: 0.8901\n",
      "\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 0.1414 Acc: 0.9489\n",
      "val Loss: 0.4777 Acc: 0.8337\n",
      "\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9486\n",
      "val Loss: 0.3117 Acc: 0.8896\n",
      "\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9535\n",
      "val Loss: 0.3968 Acc: 0.8589\n",
      "\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 0.1332 Acc: 0.9529\n",
      "val Loss: 0.4839 Acc: 0.8355\n",
      "\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9539\n",
      "val Loss: 0.4638 Acc: 0.8407\n",
      "\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 0.1267 Acc: 0.9551\n",
      "val Loss: 0.8665 Acc: 0.6976\n",
      "\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 0.1207 Acc: 0.9584\n",
      "val Loss: 0.3124 Acc: 0.8930\n",
      "\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9576\n",
      "val Loss: 0.3131 Acc: 0.8883\n",
      "\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 0.1214 Acc: 0.9579\n",
      "val Loss: 0.3089 Acc: 0.8932\n",
      "\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9582\n",
      "val Loss: 0.3261 Acc: 0.8898\n",
      "\n",
      "Training complete in 150m 1s\n",
      "Best val Acc: 0.893219\n"
     ]
    }
   ],
   "source": [
    "model_152 = train_model(model_152, criterion, optimizer_152, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T12:04:42.905120336Z",
     "start_time": "2023-06-16T09:34:41.315141170Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dir_saved_models='saved_models'\n",
    "torch.save(model_152, dir_saved_models+f'/ResNet152_16_06')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:08:15.845417910Z",
     "start_time": "2023-07-11T17:08:15.543067366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_loaded = torch.load('saved_models/ResNet152_16_06')\n",
    "model_loaded.to(device)\n",
    "model_loaded.eval()\n",
    "dl_for_all = torch.utils.data.DataLoader(dataset_all, batch_size=1, num_workers=4)\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i,l in dl_for_all:\n",
    "        i = i.to(device, dtype=torch.float32)\n",
    "        l.to(device)\n",
    "        all_outputs = model_loaded(i)\n",
    "        predictions.append(all_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-11T17:13:09.008735349Z",
     "start_time": "2023-07-11T17:08:16.944623845Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model_loaded.cpu()\n",
    "del model_loaded\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:42:53.982435329Z",
     "start_time": "2023-06-16T15:42:53.757373364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T16:01:26.762157551Z",
     "start_time": "2023-06-16T16:01:26.725691981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "19248"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T15:54:02.047667158Z",
     "start_time": "2023-06-16T15:54:02.016976474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "prrrred = [ torch.max(prediction, 1)[1] for prediction in predictions]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T16:06:32.496453506Z",
     "start_time": "2023-06-16T16:06:32.299392149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prrrred == targets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T16:06:35.273641843Z",
     "start_time": "2023-06-16T16:06:35.266507137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.47604945968412304"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good = 0\n",
    "for i in range(len(targets)):\n",
    "    if targets[i] == prrrred[i]:\n",
    "        good +=1\n",
    "good / len(targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T16:08:22.114824871Z",
     "start_time": "2023-06-16T16:08:21.633745182Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
